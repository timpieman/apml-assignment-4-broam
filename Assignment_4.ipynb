{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 – Finding the way out in a maze\n",
    "\n",
    "*Due: Friday January 27 at 17:00 CET*\n",
    "\n",
    "In the forth assignment of the course Applications of Machine Learning (INFOB3APML), you will learn to use RL algorithms to solve the practical problem of ‘robot in a maze’. The objectives of this assignment are:\n",
    "- learn to formalize a practical problem into the Markov Decision Process (MDP)\n",
    "- get familier with the OpenAI gym framework (recently renamed as Gymnasium) and use it to implement RL agents\n",
    "- use the SARSA and Q-learning algorithm to solve the ‘robot in a maze’ MDP problem\n",
    "- evaluate the results of reinforcement learning and interpret your findings\n",
    "- reflect on the difference between two type of RL algorithms\n",
    "\n",
    "In this assignment, you are going to develop a robot and find its way out in a maze. The project is divided into three parts (5 subtask):\n",
    "-\tIn the first part (1), you will get familier with the OpenAI gym/gymnasium framework. \n",
    "-\tIn the second part, based on the gym/gymnasium framework, we have implemented the environment for you (2.1). Your task is to formalize the problem as a MDP model (2.0), implement your own RL agents (2.2) and to train them for finding the shortest route to get out of a maze (2.3).\n",
    "-\tIn the third part (3), you will evaluate and interpret your results from the implemented RL agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's start with the OpenAI gym\n",
    "\n",
    "Gym/Gynasium (https://gymnasium.farama.org/) is a wide-used standard toolkit for developing and comparing reinforcement learning algorithms. Gynasium is the maintained fork of OpenAI’s Gym library (more story about this recent change if you are interested: https://farama.org/Announcing-The-Farama-Foundation).\n",
    "\n",
    "1. Gym/Gynasium makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano. \n",
    "\n",
    "2. The library is a collection of test problems — **environments** — that you can use to work out your reinforcement learning algorithms. These environments have a shared interface, allowing you to write general algorithms.\n",
    "\n",
    "First, we download & install the gym/gynasium library. Then import the gymnasium class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "daal4py 2021.3.0 requires daal==2021.2.3, which is not installed.\n",
      "scipy 1.7.1 requires numpy<1.23.0,>=1.16.5, but you have numpy 1.24.1 which is incompatible.\n",
      "numba 0.54.1 requires numpy<1.21,>=1.17, but you have numpy 1.24.1 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached gymnasium-0.27.0-py3-none-any.whl (879 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\tim19\\anaconda3\\lib\\site-packages (from gymnasium) (4.8.1)\n",
      "Collecting numpy>=1.21.0\n",
      "  Downloading numpy-1.24.1-cp39-cp39-win_amd64.whl (14.9 MB)\n",
      "Collecting shimmy<1.0,>=0.1.0\n",
      "  Using cached Shimmy-0.2.0-py3-none-any.whl (25 kB)\n",
      "Collecting jax-jumpy>=0.2.0\n",
      "  Using cached jax_jumpy-0.2.0-py3-none-any.whl (11 kB)\n",
      "Collecting gymnasium-notices>=0.0.1\n",
      "  Using cached gymnasium_notices-0.0.1-py3-none-any.whl (2.8 kB)\n",
      "Collecting typing-extensions>=4.3.0\n",
      "  Using cached typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\tim19\\anaconda3\\lib\\site-packages (from gymnasium) (2.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\tim19\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.6.0)\n",
      "Installing collected packages: numpy, typing-extensions, shimmy, jax-jumpy, gymnasium-notices, gymnasium\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "Successfully installed gymnasium-0.27.0 gymnasium-notices-0.0.1 jax-jumpy-0.2.0 numpy-1.24.1 shimmy-0.2.0 typing-extensions-4.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to explain how the RL framework of gym works. \n",
    "- An **ENVIRONMENT**, \n",
    "- You also have an **AGENT**,\n",
    "- In MDP problems (like ours), the **ENVIRONMENT** will also provides an **OBSERVATION**, which represets the state of the **ENVIRONMENT** at the current moment.\n",
    "- The agent takes an **ACTION** based on its **OBSERVATION**,\n",
    "- When a single **ACTION** is chosen and fed to our **ENVIRONMENT**, the **ENVIRONMENT** measures how good the action was taken and produces a **REWARD**, which is usually a numeric value.\n",
    "\n",
    "Please read the 'Basic usage' https://gymnasium.farama.org/content/basic_usage/ for better understanding the framework.  And do not forget import gymnasium before running other codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Go back to our own task\n",
    " \n",
    " Next, you will solve a practical MDP problem 'robot in a maze' based on the gym framework. You shall implement the RL agent and train it to find the shortest route to achieve the maze goal. In this MDP, the enviroment is a grid world (a maze) while the agent is a robot. At each time step, the robot starts at a random location and can move around in the grid world. The long-term objective is finding the way out (reaching the final location). Hence, you need to find a fixed goal position within the maze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Model the practical task into a MDP\n",
    "\n",
    "To solve a RL problem, we start with formalizing the problem into a MDP model. Please describe this MDP model in your report. \n",
    "\n",
    "Notice: No empricial data provided in this assignment, so the point of 'data description and exploration' will be given to this step. \n",
    "\n",
    "While exploring your MDP model, you shall think about questions such as:\n",
    "- What is the environment? How does it look like?\n",
    "- What simulated data can your RL agent observe from the environment? How does it look like?\n",
    "- Which data is considered as the state? Which data is considered as the reward?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set up the environment\n",
    "\n",
    "There is no need to implement your own environment. You shall use the environment we provide in the file **environment.py**. But please make sure to have a look at it, so that you understand the inner working of this environment.\n",
    "\n",
    "The core gym interface is **Env**, which is the unified environment interface. The following are the Env methods you should know:\n",
    "\n",
    "- reset(self): Reset the environment's state. Returns observation.\n",
    "- step(self, action): Step the environment by one timestep. Returns observation, reward, done, info. \n",
    "- render(self, mode='rgb_array'): Render one frame of the environment. The default mode will do something human friendly, such as pop up a window. In this assignment, there is no need to create a pop up window. \n",
    "\n",
    "Please notice that you need to first install the [mazelab](https://github.com/zuoxingdong/mazelab) package for running the environment (a file with required packages is also given). If you run the below cell the first time. Make sure to restart the ipython notebook at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/sw1989/mazelab.git\n",
    "!pip install -e mazelab\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now check whether the required packages (e.g. mazela, pandas, tqdm, seaborn) are installed. Please install the ones are missing. \n",
    "\n",
    "ATTENTION: To run the given code, please use the python version 3.7-3.9, and the numpy version < 1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conda list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a few helper functions to make it easier to debug your agents. \n",
    " - `animate_run` will enable you to see the agent's behavior. It takes a list of images which can be produced by the `env.render` function of the environment\n",
    " - `visualize_agent_brain` will provide you with a way to visualize the agents learned q_table. Use it after you have implemented and trained your agents. The first plot will show the highest q-value per state (position on the map) and the second will tell you which action the agent would choose at that state/position. It takes the environment and the agent as input.\n",
    "\n",
    "Below you will find a basic example of how the animation function works. Please notice that: whenever you **reset()** the environment, the agent will start at a random position (a different state). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The helper functions\n",
    "\n",
    "from IPython import get_ipython\n",
    "import random\n",
    "from mazelab.generators import random_maze, morris_water_maze\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from mazelab.solvers import dijkstra_solver\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from environment import TaskEnv\n",
    "from typing import Tuple, List\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def animate_run(data:List[np.ndarray]):\n",
    "    init_img = data[0]\n",
    "    remaining_img = data[1:]\n",
    "    img_container = plt.imshow(init_img)  # only call this once\n",
    "    for img in remaining_img:\n",
    "        img_container.set_data(img)  # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "def visualize_agent_brain(agent, env: TaskEnv):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax1.set_title(\"Highest state value at position (x,y)\")\n",
    "    state_value_map = agent.q_table.max(axis=2)\n",
    "    sns.heatmap(state_value_map, ax=ax1)\n",
    "\n",
    "    ax2.set_title(\"Chosen action at position (x,y)\")\n",
    "    n = env.action_space.n + 1\n",
    "    path = env.maze.objects.free.positions\n",
    "    decisions_map = np.array([[x_, y_, agent.select_action([x_, y_]) + 1] for x_, y_ in path])\n",
    "    state_action_map = np.zeros_like(agent.q_table.max(axis=2))\n",
    "    state_action_map[decisions_map[:, 0], decisions_map[:, 1]] = decisions_map[:, 2]\n",
    "    cmap = sns.color_palette(\"viridis\", n)\n",
    "    sns.heatmap(state_action_map, cmap=cmap, ax=ax2)\n",
    "    colorbar = ax2.collections[0].colorbar\n",
    "    r = (colorbar.vmax) - colorbar.vmin\n",
    "    colorbar.set_ticks([colorbar.vmin + r / n * (0.5 + i) for i in range(n)])\n",
    "    colorbar.set_ticklabels(['N/A', 'north', 'south', 'west', 'east'])\n",
    "    fig.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "env = TaskEnv()\n",
    "env.reset()\n",
    "impassable_array = env.unwrapped.maze.to_impassable()\n",
    "motions = env.unwrapped.motions\n",
    "start = env.unwrapped.maze.objects.agent.positions[0]\n",
    "goal = env.unwrapped.maze.objects.goal.positions[0]\n",
    "actions = dijkstra_solver(impassable_array, motions, start, goal)\n",
    "print(actions)\n",
    "\n",
    "imgs = []\n",
    "rewards = 0.0\n",
    "for action in actions:\n",
    "    _, reward, _, _ = env.step(action)\n",
    "    rewards += reward\n",
    "    imgs.append(env.render(\"rgb_array\"))\n",
    "print(rewards)\n",
    "\n",
    "animate_run(imgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Implement the agents \n",
    "\n",
    "In this part, you are expected to implement two RL agents. \n",
    "\n",
    "- Agent 1 uses the Q-learning algorithm to learn the optimal solution\n",
    "- Agent 2 uses the SARSA algorithm to learn the optimal solution. To decide the action to take at each time step,  this agent uses the epsilon greedy action selection.\n",
    "\n",
    "Here we also provided an example agent: Random Agent. It follows a random policy to move at each step (randomly select the action). You can use this example agent as a baseline to evaluate your agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent\n",
    "class RandomAgent():\n",
    "    def __init__(self,\n",
    "                 env: TaskEnv,\n",
    "                 exploration_rate: float = None,\n",
    "                 learning_rate: float = None,\n",
    "                 discount_factor: float = None) -> int:\n",
    "        self.epsilon = 1  # A random agent \"explores\" always, so epsilon will be 1\n",
    "        self.alpha = 0  # A random agent never learns, so there's no need for a learning rate\n",
    "        self.gamma = 0  # A random agent does not update it's q-table. Hence, it's zero.\n",
    "        self.q_table = np.zeros(env.observation_space.shape + (env.action_space.n, ), dtype=float)\n",
    "        self.actions = env.action_space\n",
    "\n",
    "    def select_action(self, state: Tuple[int, int], use_greedy_strategy: bool = False) -> int:\n",
    "        if not use_greedy_strategy:\n",
    "            if random.random() < self.epsilon:\n",
    "                next_action = self.actions.sample()\n",
    "                return next_action\n",
    "\n",
    "        x, y = state\n",
    "        max_val = np.max(self.q_table[x, y, :])\n",
    "        find_max_val = np.where(self.q_table[x, y, :] == max_val)\n",
    "        next_action = np.random.choice(find_max_val[0])\n",
    "        return next_action\n",
    "\n",
    "    def learn(self, state, action, next_state, reward, done):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    def __init__(self,\n",
    "                 env: TaskEnv,\n",
    "                 exploration_rate: float = 0.1,\n",
    "                 learning_rate: float = 0.8,\n",
    "                 discount_factor: float = 0.95) -> int:\n",
    "        self.epsilon = exploration_rate\n",
    "        self.alpha = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.q_table = np.zeros(env.observation_space.shape + (env.action_space.n, ), dtype=float)\n",
    "        self.actions = env.action_space\n",
    "\n",
    "    def select_action(self, state: Tuple[int, int], use_greedy_strategy: bool = False) -> int:\n",
    "        if not use_greedy_strategy:\n",
    "            if random.random() < self.epsilon:\n",
    "                next_action = self.actions.sample()\n",
    "                return next_action\n",
    "\n",
    "        x, y = state\n",
    "        max_val = np.max(self.q_table[x, y, :])\n",
    "        find_max_val = np.where(self.q_table[x, y, :] == max_val)\n",
    "        next_action = np.random.choice(find_max_val[0])\n",
    "        return next_action\n",
    "\n",
    "    def learn(self, state, action, next_state, reward, done):\n",
    "        x, y = state\n",
    "        x_, y_ = next_state\n",
    "        max_val = np.max(self.q_table[x_, y_, :])\n",
    "        self.q_table[x, y, action] = (1 - self.alpha) * self.q_table[x, y, action] + self.alpha * (reward + self.gamma * max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Q learning agent version 2\n",
    "# class QLearningAgent():\n",
    "#     def __init__(self,\n",
    "#                  env: TaskEnv,\n",
    "#                  exploration_rate: float = 0.1,\n",
    "#                  learning_rate: float = 0.1,\n",
    "#                  discount_factor: float = 0.9) -> int:\n",
    "#         self.epsilon = exploration_rate\n",
    "#         self.alpha = learning_rate\n",
    "#         self.gamma = discount_factor\n",
    "#         self.q_table = np.zeros(env.observation_space.shape + (env.action_space.n, ), dtype=float)\n",
    "#         self.actions = env.action_space\n",
    "\n",
    "#     def select_action(self, state: Tuple[int, int], use_greedy_strategy: bool = False) -> int:\n",
    "#         if not use_greedy_strategy:\n",
    "#             if random.random() < self.epsilon:\n",
    "#                 next_action = self.actions.sample()\n",
    "#                 return next_action\n",
    "\n",
    "#         x, y = state\n",
    "#         max_val = np.max(self.q_table[x, y, :])\n",
    "#         find_max_val = np.where(self.q_table[x, y, :] == max_val)\n",
    "#         next_action = np.random.choice(find_max_val[0])\n",
    "#         return next_action\n",
    "\n",
    "#     def learn(self, state, action, next_state, reward, done):\n",
    "#         x,y = state\n",
    "#         x_,y_ = next_state\n",
    "#         max_next_q = max(self.q_table[x_,y_,:])\n",
    "#         self.q_table[x,y,action] = self.q_table[x,y,action] + self.alpha * (reward + self.gamma * max_next_q - self.q_table[x,y,action])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run the simulation\n",
    "\n",
    "Now, we write the codes for running a simulation. In each run, you shall setup the epsilon parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [40], line 20\u001b[0m\n\u001b[0;32m     16\u001b[0m     imgs\u001b[39m.\u001b[39mappend(env\u001b[39m.\u001b[39mrender(\u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[39mprint\u001b[39m(rewards)\n\u001b[1;32m---> 20\u001b[0m animate_run(imgs)\n\u001b[0;32m     21\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn [26], line 53\u001b[0m, in \u001b[0;36manimate_run\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m remaining_img:\n\u001b[0;32m     52\u001b[0m     img_container\u001b[39m.\u001b[39mset_data(img)  \u001b[39m# just update the data\u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m     display\u001b[39m.\u001b[39;49mdisplay(plt\u001b[39m.\u001b[39;49mgcf())\n\u001b[0;32m     54\u001b[0m     display\u001b[39m.\u001b[39mclear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[0;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    176\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[0;32m    340\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    341\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 151\u001b[0m fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(bytes_io, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    152\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backend_bases.py:2319\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2315\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   2316\u001b[0m     \u001b[39m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[0;32m   2317\u001b[0m     \u001b[39m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[0;32m   2318\u001b[0m     \u001b[39mwith\u001b[39;00m cbook\u001b[39m.\u001b[39m_setattr_cm(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure, dpi\u001b[39m=\u001b[39mdpi):\n\u001b[1;32m-> 2319\u001b[0m         result \u001b[39m=\u001b[39m print_method(\n\u001b[0;32m   2320\u001b[0m             filename,\n\u001b[0;32m   2321\u001b[0m             facecolor\u001b[39m=\u001b[39mfacecolor,\n\u001b[0;32m   2322\u001b[0m             edgecolor\u001b[39m=\u001b[39medgecolor,\n\u001b[0;32m   2323\u001b[0m             orientation\u001b[39m=\u001b[39morientation,\n\u001b[0;32m   2324\u001b[0m             bbox_inches_restore\u001b[39m=\u001b[39m_bbox_inches_restore,\n\u001b[0;32m   2325\u001b[0m             \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   2326\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   2327\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39mand\u001b[39;00m restore_bbox:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backend_bases.py:1648\u001b[0m, in \u001b[0;36m_check_savefig_extra_args.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1640\u001b[0m     _api\u001b[39m.\u001b[39mwarn_deprecated(\n\u001b[0;32m   1641\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m3.3\u001b[39m\u001b[39m'\u001b[39m, name\u001b[39m=\u001b[39mname, removal\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m3.6\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1642\u001b[0m         message\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%(name)s\u001b[39;00m\u001b[39m() got unexpected keyword argument \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1643\u001b[0m                 \u001b[39m+\u001b[39m arg \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m which is no longer supported as of \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1644\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%(since)s\u001b[39;00m\u001b[39m and will become an error \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1645\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m%(removal)s\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m   1646\u001b[0m     kwargs\u001b[39m.\u001b[39mpop(arg)\n\u001b[1;32m-> 1648\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:415\u001b[0m, in \u001b[0;36mdelete_parameter.<locals>.wrapper\u001b[1;34m(*inner_args, **inner_kwargs)\u001b[0m\n\u001b[0;32m    405\u001b[0m     deprecation_addendum \u001b[39m=\u001b[39m (\n\u001b[0;32m    406\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIf any parameter follows \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m!r}\u001b[39;00m\u001b[39m, they should be passed as \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    407\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mkeyword, not positionally.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    408\u001b[0m     warn_deprecated(\n\u001b[0;32m    409\u001b[0m         since,\n\u001b[0;32m    410\u001b[0m         name\u001b[39m=\u001b[39m\u001b[39mrepr\u001b[39m(name),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    413\u001b[0m                  \u001b[39melse\u001b[39;00m deprecation_addendum,\n\u001b[0;32m    414\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 415\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39minner_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minner_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:540\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[1;34m(self, filename_or_obj, metadata, pil_kwargs, *args)\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[39m@_check_savefig_extra_args\u001b[39m\n\u001b[0;32m    491\u001b[0m \u001b[39m@_api\u001b[39m\u001b[39m.\u001b[39mdelete_parameter(\u001b[39m\"\u001b[39m\u001b[39m3.5\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39margs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    492\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprint_png\u001b[39m(\u001b[39mself\u001b[39m, filename_or_obj, \u001b[39m*\u001b[39margs,\n\u001b[0;32m    493\u001b[0m               metadata\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pil_kwargs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    494\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[39m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[39m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 540\u001b[0m     FigureCanvasAgg\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    541\u001b[0m     mpl\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimsave(\n\u001b[0;32m    542\u001b[0m         filename_or_obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer_rgba(), \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpng\u001b[39m\u001b[39m\"\u001b[39m, origin\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mupper\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    543\u001b[0m         dpi\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39mdpi, metadata\u001b[39m=\u001b[39mmetadata, pil_kwargs\u001b[39m=\u001b[39mpil_kwargs)\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:436\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[39m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[0;32m    433\u001b[0m \u001b[39mwith\u001b[39;00m RendererAgg\u001b[39m.\u001b[39mlock, \\\n\u001b[0;32m    434\u001b[0m      (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\u001b[39m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoolbar\n\u001b[0;32m    435\u001b[0m       \u001b[39melse\u001b[39;00m nullcontext()):\n\u001b[1;32m--> 436\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrenderer)\n\u001b[0;32m    437\u001b[0m     \u001b[39m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[0;32m    438\u001b[0m     \u001b[39m# don't forget to call the superclass.\u001b[39;00m\n\u001b[0;32m    439\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mdraw()\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\figure.py:2845\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   2842\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   2844\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 2845\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   2846\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   2848\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   2849\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axes\\_base.py:3091\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3088\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m   3089\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> 3091\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3092\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3094\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3095\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\image.py:132\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    131\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 132\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    133\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    135\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axis.py:1163\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1159\u001b[0m ticklabelBoxes, ticklabelBoxes2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_tick_bboxes(ticks_to_draw,\n\u001b[0;32m   1160\u001b[0m                                                         renderer)\n\u001b[0;32m   1162\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n\u001b[1;32m-> 1163\u001b[0m     tick\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m   1165\u001b[0m \u001b[39m# scale up the axis label box to also find the neighbors, not\u001b[39;00m\n\u001b[0;32m   1166\u001b[0m \u001b[39m# just the tick labels that actually overlap note we need a\u001b[39;00m\n\u001b[0;32m   1167\u001b[0m \u001b[39m# *copy* of the axis label box because we don't want to scale\u001b[39;00m\n\u001b[0;32m   1168\u001b[0m \u001b[39m# the actual bbox\u001b[39;00m\n\u001b[0;32m   1170\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_label_position(renderer)\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\axis.py:299\u001b[0m, in \u001b[0;36mTick.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    296\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[0;32m    297\u001b[0m \u001b[39mfor\u001b[39;00m artist \u001b[39min\u001b[39;00m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgridline, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick1line, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtick2line,\n\u001b[0;32m    298\u001b[0m                \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel1, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabel2]:\n\u001b[1;32m--> 299\u001b[0m     artist\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    300\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    301\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\text.py:733\u001b[0m, in \u001b[0;36mText.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    729\u001b[0m             textrenderer\u001b[39m.\u001b[39mdraw_tex(gc, x, y, clean_line,\n\u001b[0;32m    730\u001b[0m                                   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fontproperties, angle,\n\u001b[0;32m    731\u001b[0m                                   mtext\u001b[39m=\u001b[39mmtext)\n\u001b[0;32m    732\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 733\u001b[0m             textrenderer\u001b[39m.\u001b[39;49mdraw_text(gc, x, y, clean_line,\n\u001b[0;32m    734\u001b[0m                                    \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fontproperties, angle,\n\u001b[0;32m    735\u001b[0m                                    ismath\u001b[39m=\u001b[39;49mismath, mtext\u001b[39m=\u001b[39;49mmtext)\n\u001b[0;32m    737\u001b[0m gc\u001b[39m.\u001b[39mrestore()\n\u001b[0;32m    738\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tim19\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py:237\u001b[0m, in \u001b[0;36mRendererAgg.draw_text\u001b[1;34m(self, gc, x, y, s, prop, angle, ismath, mtext)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    235\u001b[0m \u001b[39m# We pass '0' for angle here, since it will be rotated (in raster\u001b[39;00m\n\u001b[0;32m    236\u001b[0m \u001b[39m# space) in the following call to draw_text_image).\u001b[39;00m\n\u001b[1;32m--> 237\u001b[0m font\u001b[39m.\u001b[39;49mset_text(s, \u001b[39m0\u001b[39;49m, flags\u001b[39m=\u001b[39;49mflags)\n\u001b[0;32m    238\u001b[0m font\u001b[39m.\u001b[39mdraw_glyphs_to_bitmap(\n\u001b[0;32m    239\u001b[0m     antialiased\u001b[39m=\u001b[39mmpl\u001b[39m.\u001b[39mrcParams[\u001b[39m'\u001b[39m\u001b[39mtext.antialiased\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    240\u001b[0m d \u001b[39m=\u001b[39m font\u001b[39m.\u001b[39mget_descent() \u001b[39m/\u001b[39m \u001b[39m64.0\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = QLearningAgent(env)\n",
    "\n",
    "imgs = []\n",
    "rewards = 0.0\n",
    "state = env.reset()\n",
    "goal_pos = env.unwrapped.maze.objects.goal.positions[0]\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.select_action(state)\n",
    "    next_state, reward, _, _ = env.step(action)\n",
    "    if next_state == goal_pos:\n",
    "        done = True\n",
    "    state = next_state\n",
    "    rewards += reward\n",
    "    imgs.append(env.render(\"rgb_array\"))\n",
    "\n",
    "print(rewards)\n",
    "\n",
    "animate_run(imgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Play with parameters and analyse results\n",
    " \n",
    "Finally, you will describe, evaluate and interpret your results from two RL agents, as well as compare your agents with the given Random agent. Feel free to use the provided helper functions for evaluating your agents. Some points are good to notice:\n",
    "\n",
    "- Both quantified evaluation and human evaluation are needed in the report. The quantified evaluation shall focus on the measurement of reward. In human evaluation, you can use the provided visual tools to interpret your results. Your report shall include at least one plot presenting comparable measures of the different agents. \n",
    "\n",
    "- While evaluating the results of Agent 2 (with SARSA algorithm), please try at least 2 different values of **epsilon** (expect 0) and discuss the influence of different epsilon values on results. In the end, please identify a reasonable epsilon value that could balance the exploration and exploitation, then fix this value for comparing two agents. Present your trails and results in the report.\n",
    "\n",
    "- In the report, you also need to parcitularly describe and discuss the similarity and difference of results from two RL agents (hint: on-policy VS off-policy). For this, please make sure that the compared results are obtained from the same environment (a same maze for two different agents). Also, while evaluating the results of two agents, please try at least 2 different values of **gamma**. In this way, you could discuss the influence of this discount factor in your report. \n",
    "\n",
    "- Please run the simulation for multiple times and average them for all your results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Tasks \n",
    "\n",
    "We would like to challenge you with the following bonus task. For each task that is successfully completed, you may obtain max. 1 extra point. \n",
    "\n",
    "1. Implement a third RL agent using another RL algorithm (e.g. Monte Carlo methods, Expected SARSA or even neural network-based ones) and discuss your findings. Compare this third agent with the above ones and explain why this is a better (or worse) RL algorithm. You are allowed to reuse exsiting packages, but please cite them, test them in advance, and make sure that you can explain the used algorithm using your own words.\n",
    "\n",
    "2. Can you explore and show other evaluation results? If so, implement and present one extra result (e.g. a plot). And please explain why it is a good evaluation for our task or how it shows the difference between two RL agents/algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "7d23ce8f6a59134e79a0198c12c88cfa5f56d45eb2f0aec4416bb561bd372b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
