{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4 – Finding the way out in a maze\n",
    "\n",
    "*Due: Friday January 27 at 17:00 CET*\n",
    "\n",
    "In the forth assignment of the course Applications of Machine Learning (INFOB3APML), you will learn to use RL algorithms to solve the practical problem of ‘robot in a maze’. The objectives of this assignment are:\n",
    "- learn to formalize a practical problem into the Markov Decision Process (MDP)\n",
    "- get familier with the OpenAI gym framework (recently renamed as Gymnasium) and use it to implement RL agents\n",
    "- use the SARSA and Q-learning algorithm to solve the ‘robot in a maze’ MDP problem\n",
    "- evaluate the results of reinforcement learning and interpret your findings\n",
    "- reflect on the difference between two type of RL algorithms\n",
    "\n",
    "In this assignment, you are going to develop a robot and find its way out in a maze. The project is divided into three parts (5 subtask):\n",
    "-\tIn the first part (1), you will get familier with the OpenAI gym/gymnasium framework. \n",
    "-\tIn the second part, based on the gym/gymnasium framework, we have implemented the environment for you (2.1). Your task is to formalize the problem as a MDP model (2.0), implement your own RL agents (2.2) and to train them for finding the shortest route to get out of a maze (2.3).\n",
    "-\tIn the third part (3), you will evaluate and interpret your results from the implemented RL agents.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Let's start with the OpenAI gym\n",
    "\n",
    "Gym/Gynasium (https://gymnasium.farama.org/) is a wide-used standard toolkit for developing and comparing reinforcement learning algorithms. Gynasium is the maintained fork of OpenAI’s Gym library (more story about this recent change if you are interested: https://farama.org/Announcing-The-Farama-Foundation).\n",
    "\n",
    "1. Gym/Gynasium makes no assumptions about the structure of your agent, and is compatible with any numerical computation library, such as TensorFlow or Theano. \n",
    "\n",
    "2. The library is a collection of test problems — **environments** — that you can use to work out your reinforcement learning algorithms. These environments have a shared interface, allowing you to write general algorithms.\n",
    "\n",
    "First, we download & install the gym/gynasium library. Then import the gymnasium class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.27.0)\n",
      "Requirement already satisfied: gymnasium-notices>=0.0.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (0.0.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (4.12.0)\n",
      "Requirement already satisfied: jax-jumpy>=0.2.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (1.23.3)\n",
      "Requirement already satisfied: shimmy<1.0,>=0.1.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (0.2.0)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (2.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gymnasium) (4.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.8.0->gymnasium) (3.8.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to explain how the RL framework of gym works. \n",
    "- An **ENVIRONMENT**, \n",
    "- You also have an **AGENT**,\n",
    "- In MDP problems (like ours), the **ENVIRONMENT** will also provides an **OBSERVATION**, which represets the state of the **ENVIRONMENT** at the current moment.\n",
    "- The agent takes an **ACTION** based on its **OBSERVATION**,\n",
    "- When a single **ACTION** is chosen and fed to our **ENVIRONMENT**, the **ENVIRONMENT** measures how good the action was taken and produces a **REWARD**, which is usually a numeric value.\n",
    "\n",
    "Please read the 'Basic usage' https://gymnasium.farama.org/content/basic_usage/ for better understanding the framework.  And do not forget import gymnasium before running other codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 2. Go back to our own task\n",
    " \n",
    " Next, you will solve a practical MDP problem 'robot in a maze' based on the gym framework. You shall implement the RL agent and train it to find the shortest route to achieve the maze goal. In this MDP, the enviroment is a grid world (a maze) while the agent is a robot. At each time step, the robot starts at a random location and can move around in the grid world. The long-term objective is finding the way out (reaching the final location). Hence, you need to find a fixed goal position within the maze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Model the practical task into a MDP\n",
    "\n",
    "To solve a RL problem, we start with formalizing the problem into a MDP model. Please describe this MDP model in your report. \n",
    "\n",
    "Notice: No empricial data provided in this assignment, so the point of 'data description and exploration' will be given to this step. \n",
    "\n",
    "While exploring your MDP model, you shall think about questions such as:\n",
    "- What is the environment? How does it look like?\n",
    "- What simulated data can your RL agent observe from the environment? How does it look like?\n",
    "- Which data is considered as the state? Which data is considered as the reward?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Set up the environment\n",
    "\n",
    "There is no need to implement your own environment. You shall use the environment we provide in the file **environment.py**. But please make sure to have a look at it, so that you understand the inner working of this environment.\n",
    "\n",
    "The core gym interface is **Env**, which is the unified environment interface. The following are the Env methods you should know:\n",
    "\n",
    "- reset(self): Reset the environment's state. Returns observation.\n",
    "- step(self, action): Step the environment by one timestep. Returns observation, reward, done, info. \n",
    "- render(self, mode='rgb_array'): Render one frame of the environment. The default mode will do something human friendly, such as pop up a window. In this assignment, there is no need to create a pop up window. \n",
    "\n",
    "Please notice that you need to first install the [mazelab](https://github.com/zuoxingdong/mazelab) package for running the environment (a file with required packages is also given). If you run the below cell the first time. Make sure to restart the ipython notebook at least once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'mazelab' already exists and is not an empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Jeroen/Documents/GitHub/apml-assignment-4-broam/mazelab\n",
      "Requirement already satisfied: gym in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mazelab==0.2.0) (0.26.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mazelab==0.2.0) (1.23.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mazelab==0.2.0) (3.6.0)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from mazelab==0.2.0) (0.19.3)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym->mazelab==0.2.0) (4.12.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym->mazelab==0.2.0) (0.0.8)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym->mazelab==0.2.0) (2.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.8.0->gym->mazelab==0.2.0) (3.8.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (1.0.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->mazelab==0.2.0) (4.37.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jeroen\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib->mazelab==0.2.0) (1.15.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->mazelab==0.2.0) (2.24.0)\n",
      "Requirement already satisfied: networkx>=2.2 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->mazelab==0.2.0) (3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->mazelab==0.2.0) (2022.10.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->mazelab==0.2.0) (1.4.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->mazelab==0.2.0) (1.9.1)\n",
      "Installing collected packages: mazelab\n",
      "  Attempting uninstall: mazelab\n",
      "    Found existing installation: mazelab 0.2.0\n",
      "    Uninstalling mazelab-0.2.0:\n",
      "      Successfully uninstalled mazelab-0.2.0\n",
      "  Running setup.py develop for mazelab\n",
      "Successfully installed mazelab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.23.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jeroen\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.1->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.12.1)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (1.23.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from seaborn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.5)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.37.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas>=0.25->seaborn) (2022.2.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jeroen\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.1.3; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\users\\jeroen\\appdata\\local\\programs\\python\\python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/sw1989/mazelab.git\n",
    "!pip install -e mazelab\n",
    "!pip install pandas\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now check whether the required packages (e.g. mazela, pandas, tqdm, seaborn) are installed. Please install the ones are missing. \n",
    "\n",
    "ATTENTION: To run the given code, please use the python version 3.7-3.9, and the numpy version < 1.23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also provide a few helper functions to make it easier to debug your agents. \n",
    " - `animate_run` will enable you to see the agent's behavior. It takes a list of images which can be produced by the `env.render` function of the environment\n",
    " - `visualize_agent_brain` will provide you with a way to visualize the agents learned q_table. Use it after you have implemented and trained your agents. The first plot will show the highest q-value per state (position on the map) and the second will tell you which action the agent would choose at that state/position. It takes the environment and the agent as input.\n",
    "\n",
    "Below you will find a basic example of how the animation function works. Please notice that: whenever you **reset()** the environment, the agent will start at a random position (a different state). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The helper functions\n",
    "\n",
    "from IPython import get_ipython\n",
    "import random\n",
    "from mazelab.generators import random_maze, morris_water_maze\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from mazelab.solvers import dijkstra_solver\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "from environment import TaskEnv\n",
    "from typing import Tuple, List\n",
    "import itertools as it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def animate_run(data:List[np.ndarray]):\n",
    "    init_img = data[0]\n",
    "    remaining_img = data[1:]\n",
    "    img_container = plt.imshow(init_img)  # only call this once\n",
    "    for img in remaining_img:\n",
    "        img_container.set_data(img)  # just update the data\n",
    "        display.display(plt.gcf())\n",
    "        display.clear_output(wait=True)\n",
    "\n",
    "\n",
    "def visualize_agent_brain(agent, env: TaskEnv):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax1.set_title(\"Highest state value at position (x,y)\")\n",
    "    state_value_map = agent.q_table.max(axis=2)\n",
    "    sns.heatmap(state_value_map, ax=ax1)\n",
    "\n",
    "    ax2.set_title(\"Chosen action at position (x,y)\")\n",
    "    n = env.action_space.n + 1\n",
    "    path = env.maze.objects.free.positions\n",
    "    decisions_map = np.array([[x_, y_, agent.select_action([x_, y_]) + 1] for x_, y_ in path])\n",
    "    state_action_map = np.zeros_like(agent.q_table.max(axis=2))\n",
    "    state_action_map[decisions_map[:, 0], decisions_map[:, 1]] = decisions_map[:, 2]\n",
    "    cmap = sns.color_palette(\"viridis\", n)\n",
    "    sns.heatmap(state_action_map, cmap=cmap, ax=ax2)\n",
    "    colorbar = ax2.collections[0].colorbar\n",
    "    r = (colorbar.vmax) - colorbar.vmin\n",
    "    colorbar.set_ticks([colorbar.vmin + r / n * (0.5 + i) for i in range(n)])\n",
    "    colorbar.set_ticklabels(['N/A', 'north', 'south', 'west', 'east'])\n",
    "    fig.tight_layout()\n",
    "    return plt.show()\n",
    "\n",
    "\n",
    "env = TaskEnv()\n",
    "env.reset()\n",
    "impassable_array = env.unwrapped.maze.to_impassable()\n",
    "motions = env.unwrapped.motions\n",
    "start = env.unwrapped.maze.objects.agent.positions[0]\n",
    "goal = env.unwrapped.maze.objects.goal.positions[0]\n",
    "actions = dijkstra_solver(impassable_array, motions, start, goal)\n",
    "print(actions)\n",
    "\n",
    "imgs = []\n",
    "rewards = 0.0\n",
    "for action in actions:\n",
    "    _, reward, _, _ = env.step(action)\n",
    "    rewards += reward\n",
    "    imgs.append(env.render(\"rgb_array\"))\n",
    "print(rewards)\n",
    "\n",
    "animate_run(imgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2  Implement the agents \n",
    "\n",
    "In this part, you are expected to implement two RL agents. \n",
    "\n",
    "- Agent 1 uses the Q-learning algorithm to learn the optimal solution\n",
    "- Agent 2 uses the SARSA algorithm to learn the optimal solution. To decide the action to take at each time step,  this agent uses the epsilon greedy action selection.\n",
    "\n",
    "Here we also provided an example agent: Random Agent. It follows a random policy to move at each step (randomly select the action). You can use this example agent as a baseline to evaluate your agents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random agent\n",
    "class RandomAgent():\n",
    "    def __init__(self,\n",
    "                 env: TaskEnv,\n",
    "                 exploration_rate: float = None,\n",
    "                 learning_rate: float = None,\n",
    "                 discount_factor: float = None) -> int:\n",
    "        self.epsilon = 1  # A random agent \"explores\" always, so epsilon will be 1\n",
    "        self.alpha = 0  # A random agent never learns, so there's no need for a learning rate\n",
    "        self.gamma = 0  # A random agent does not update it's q-table. Hence, it's zero.\n",
    "        self.q_table = np.zeros(env.observation_space.shape + (env.action_space.n, ), dtype=float)\n",
    "        self.actions = env.action_space\n",
    "\n",
    "    def select_action(self, state: Tuple[int, int], use_greedy_strategy: bool = False) -> int:\n",
    "        if not use_greedy_strategy:\n",
    "            if random.random() < self.epsilon:\n",
    "                next_action = self.actions.sample()\n",
    "                return next_action\n",
    "\n",
    "        x, y = state\n",
    "        max_val = np.max(self.q_table[x, y, :])\n",
    "        find_max_val = np.where(self.q_table[x, y, :] == max_val)\n",
    "        next_action = np.random.choice(find_max_val[0])\n",
    "        return next_action\n",
    "\n",
    "    def learn(self, state, action, next_state, reward, done):\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearningAgent():\n",
    "    def __init__(self,\n",
    "                 env: TaskEnv,\n",
    "                 exploration_rate: float = 0.1,\n",
    "                 learning_rate: float = 0.8,\n",
    "                 discount_factor: float = 0.95) -> int:\n",
    "        self.epsilon = exploration_rate\n",
    "        self.alpha = learning_rate\n",
    "        self.gamma = discount_factor\n",
    "        self.q_table = np.zeros(env.observation_space.shape + (env.action_space.n, ), dtype=float)\n",
    "        self.actions = env.action_space\n",
    "\n",
    "    def select_action(self, state: Tuple[int, int], use_greedy_strategy: bool = False) -> int:\n",
    "        if not use_greedy_strategy:\n",
    "            if random.random() < self.epsilon:\n",
    "                next_action = self.actions.sample()\n",
    "                return next_action\n",
    "\n",
    "        x, y = state\n",
    "        max_val = np.max(self.q_table[x, y, :])\n",
    "        find_max_val = np.where(self.q_table[x, y, :] == max_val)\n",
    "        next_action = np.random.choice(find_max_val[0])\n",
    "        return next_action\n",
    "\n",
    "    def learn(self, state, action, next_state, reward, done):\n",
    "        x, y = state\n",
    "        x_, y_ = next_state\n",
    "        max_val = np.max(self.q_table[x_, y_, :])\n",
    "        self.q_table[x, y, action] = (1 - self.alpha) * self.q_table[x, y, action] + self.alpha * (reward + self.gamma * max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarsaAgent():\n",
    "    def __init__(self,\n",
    "                 env: TaskEnv,\n",
    "                 exploration_rate: float = None,\n",
    "                 learning_rate: float = None,\n",
    "                 discount_factor: float = None) -> int:\n",
    "        self.epsilon = 0.6  # A random agent \"explores\" always, so epsilon will be 1\n",
    "        self.alpha = 0.5  # A random agent never learns, so there's no need for a learning rate\n",
    "        self.gamma = 0  # A random agent does not update it's q-table. Hence, it's zero.\n",
    "        self.q_table = np.zeros(env.observation_space.shape + (env.action_space.n, ), dtype=float)\n",
    "        self.actions = env.action_space\n",
    "\n",
    "    def select_action(self, state: Tuple[int, int], use_greedy_strategy: bool = False) -> int:\n",
    "        action = 0\n",
    "        epsilon = 0.9\n",
    "        if np.random.uniform(0,1) < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            action = np.argmax(self.q_table[state, :])\n",
    "        return action\n",
    "\n",
    "    def update(state, state2, reward, action, action2): \n",
    "        predict = self.q_table[state, action] \n",
    "        target = reward + gamma * self.q_table[state2, action2] \n",
    "        q_table[state, action] = self.q_table[state, action] + alpha * (target - predict)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Run the simulation\n",
    "\n",
    "Now, we write the codes for running a simulation. In each run, you shall setup the epsilon parameter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 21\u001b[0m\n\u001b[0;32m     17\u001b[0m     imgs\u001b[39m.\u001b[39mappend(env\u001b[39m.\u001b[39mrender(\u001b[39m\"\u001b[39m\u001b[39mrgb_array\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m     19\u001b[0m \u001b[39mprint\u001b[39m(rewards)\n\u001b[1;32m---> 21\u001b[0m animate_run(imgs)\n\u001b[0;32m     22\u001b[0m plt\u001b[39m.\u001b[39mshow()\n",
      "Cell \u001b[1;32mIn [4], line 24\u001b[0m, in \u001b[0;36manimate_run\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfor\u001b[39;00m img \u001b[39min\u001b[39;00m remaining_img:\n\u001b[0;32m     23\u001b[0m     img_container\u001b[39m.\u001b[39mset_data(img)  \u001b[39m# just update the data\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m     display\u001b[39m.\u001b[39;49mdisplay(plt\u001b[39m.\u001b[39;49mgcf())\n\u001b[0;32m     25\u001b[0m     display\u001b[39m.\u001b[39mclear_output(wait\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[39m=\u001b[39mobj, metadata\u001b[39m=\u001b[39mmetadata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[39m=\u001b[39m \u001b[39mformat\u001b[39;49m(obj, include\u001b[39m=\u001b[39;49minclude, exclude\u001b[39m=\u001b[39;49mexclude)\n\u001b[0;32m    299\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[39m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\formatters.py:178\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    176\u001b[0m md \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m     data \u001b[39m=\u001b[39m formatter(obj)\n\u001b[0;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    180\u001b[0m     \u001b[39m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    181\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[39m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[39mreturn\u001b[39;00m caller(func, \u001b[39m*\u001b[39m(extras \u001b[39m+\u001b[39m args), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\formatters.py:222\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[39m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m     r \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    223\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    224\u001b[0m     \u001b[39m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    225\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_return(\u001b[39mNone\u001b[39;00m, args[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\formatters.py:339\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m    338\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 339\u001b[0m     \u001b[39mreturn\u001b[39;00m printer(obj)\n\u001b[0;32m    340\u001b[0m \u001b[39m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    341\u001b[0m method \u001b[39m=\u001b[39m get_real_method(obj, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_method)\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\IPython\\core\\pylabtools.py:151\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mbackend_bases\u001b[39;00m \u001b[39mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    149\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 151\u001b[0m fig\u001b[39m.\u001b[39mcanvas\u001b[39m.\u001b[39mprint_figure(bytes_io, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n\u001b[0;32m    152\u001b[0m data \u001b[39m=\u001b[39m bytes_io\u001b[39m.\u001b[39mgetvalue()\n\u001b[0;32m    153\u001b[0m \u001b[39mif\u001b[39;00m fmt \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39msvg\u001b[39m\u001b[39m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\backend_bases.py:2314\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2308\u001b[0m     renderer \u001b[39m=\u001b[39m _get_renderer(\n\u001b[0;32m   2309\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure,\n\u001b[0;32m   2310\u001b[0m         functools\u001b[39m.\u001b[39mpartial(\n\u001b[0;32m   2311\u001b[0m             print_method, orientation\u001b[39m=\u001b[39morientation)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2313\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mgetattr\u001b[39m(renderer, \u001b[39m\"\u001b[39m\u001b[39m_draw_disabled\u001b[39m\u001b[39m\"\u001b[39m, nullcontext)():\n\u001b[1;32m-> 2314\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m   2316\u001b[0m \u001b[39mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2317\u001b[0m     \u001b[39mif\u001b[39;00m bbox_inches \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtight\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\artist.py:74\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[39m@wraps\u001b[39m(draw)\n\u001b[0;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdraw_wrapper\u001b[39m(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m---> 74\u001b[0m     result \u001b[39m=\u001b[39m draw(artist, renderer, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     75\u001b[0m     \u001b[39mif\u001b[39;00m renderer\u001b[39m.\u001b[39m_rasterizing:\n\u001b[0;32m     76\u001b[0m         renderer\u001b[39m.\u001b[39mstop_rasterizing()\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\figure.py:3069\u001b[0m, in \u001b[0;36mFigure.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3066\u001b[0m         \u001b[39m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[0;32m   3068\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpatch\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[1;32m-> 3069\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3070\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3072\u001b[0m \u001b[39mfor\u001b[39;00m sfig \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msubfigs:\n\u001b[0;32m   3073\u001b[0m     sfig\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axes\\_base.py:3106\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   3103\u001b[0m         a\u001b[39m.\u001b[39mdraw(renderer)\n\u001b[0;32m   3104\u001b[0m     renderer\u001b[39m.\u001b[39mstop_rasterizing()\n\u001b[1;32m-> 3106\u001b[0m mimage\u001b[39m.\u001b[39;49m_draw_list_compositing_images(\n\u001b[0;32m   3107\u001b[0m     renderer, \u001b[39mself\u001b[39;49m, artists, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfigure\u001b[39m.\u001b[39;49msuppressComposite)\n\u001b[0;32m   3109\u001b[0m renderer\u001b[39m.\u001b[39mclose_group(\u001b[39m'\u001b[39m\u001b[39maxes\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m   3110\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstale \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39mif\u001b[39;00m not_composite \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m has_images:\n\u001b[0;32m    130\u001b[0m     \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m artists:\n\u001b[1;32m--> 131\u001b[0m         a\u001b[39m.\u001b[39;49mdraw(renderer)\n\u001b[0;32m    132\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m     \u001b[39m# Composite any adjacent images together\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     image_group \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\artist.py:51\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[1;34m(artist, renderer)\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     49\u001b[0m         renderer\u001b[39m.\u001b[39mstart_filter()\n\u001b[1;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m draw(artist, renderer)\n\u001b[0;32m     52\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     \u001b[39mif\u001b[39;00m artist\u001b[39m.\u001b[39mget_agg_filter() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axis.py:1305\u001b[0m, in \u001b[0;36mAxis.draw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1302\u001b[0m renderer\u001b[39m.\u001b[39mopen_group(\u001b[39m__name__\u001b[39m, gid\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_gid())\n\u001b[0;32m   1304\u001b[0m ticks_to_draw \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_ticks()\n\u001b[1;32m-> 1305\u001b[0m tlb1, tlb2 \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_ticklabel_bboxes(ticks_to_draw, renderer)\n\u001b[0;32m   1307\u001b[0m \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks_to_draw:\n\u001b[0;32m   1308\u001b[0m     tick\u001b[39m.\u001b[39mdraw(renderer)\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axis.py:1232\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[1;34m(self, ticks, renderer)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1231\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1232\u001b[0m \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1233\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[0;32m   1234\u001b[0m         [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1235\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\axis.py:1232\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1230\u001b[0m \u001b[39mif\u001b[39;00m renderer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1231\u001b[0m     renderer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfigure\u001b[39m.\u001b[39m_get_renderer()\n\u001b[1;32m-> 1232\u001b[0m \u001b[39mreturn\u001b[39;00m ([tick\u001b[39m.\u001b[39;49mlabel1\u001b[39m.\u001b[39;49mget_window_extent(renderer)\n\u001b[0;32m   1233\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel1\u001b[39m.\u001b[39mget_visible()],\n\u001b[0;32m   1234\u001b[0m         [tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_window_extent(renderer)\n\u001b[0;32m   1235\u001b[0m          \u001b[39mfor\u001b[39;00m tick \u001b[39min\u001b[39;00m ticks \u001b[39mif\u001b[39;00m tick\u001b[39m.\u001b[39mlabel2\u001b[39m.\u001b[39mget_visible()])\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\text.py:918\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[1;34m(self, renderer, dpi)\u001b[0m\n\u001b[0;32m    916\u001b[0m bbox, info, descent \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_layout(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_renderer)\n\u001b[0;32m    917\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_unitless_position()\n\u001b[1;32m--> 918\u001b[0m x, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_transform()\u001b[39m.\u001b[39;49mtransform((x, y))\n\u001b[0;32m    919\u001b[0m bbox \u001b[39m=\u001b[39m bbox\u001b[39m.\u001b[39mtranslated(x, y)\n\u001b[0;32m    920\u001b[0m \u001b[39mreturn\u001b[39;00m bbox\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:1490\u001b[0m, in \u001b[0;36mTransform.transform\u001b[1;34m(self, values)\u001b[0m\n\u001b[0;32m   1487\u001b[0m values \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_dims))\n\u001b[0;32m   1489\u001b[0m \u001b[39m# Transform the values\u001b[39;00m\n\u001b[1;32m-> 1490\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_affine(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform_non_affine(values))\n\u001b[0;32m   1492\u001b[0m \u001b[39m# Convert the result back to the shape of the input values.\u001b[39;00m\n\u001b[0;32m   1493\u001b[0m \u001b[39mif\u001b[39;00m ndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:2420\u001b[0m, in \u001b[0;36mCompositeGenericTransform.transform_affine\u001b[1;34m(self, points)\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform_affine\u001b[39m(\u001b[39mself\u001b[39m, points):\n\u001b[0;32m   2419\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[1;32m-> 2420\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39mtransform(points)\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:2447\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_b\u001b[39m.\u001b[39mget_affine()\n\u001b[0;32m   2445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   2446\u001b[0m     \u001b[39mreturn\u001b[39;00m Affine2D(np\u001b[39m.\u001b[39mdot(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_b\u001b[39m.\u001b[39mget_affine()\u001b[39m.\u001b[39mget_matrix(),\n\u001b[1;32m-> 2447\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39mget_matrix()))\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:2262\u001b[0m, in \u001b[0;36mBlendedGenericTransform.get_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_affine\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   2260\u001b[0m     \u001b[39m# docstring inherited\u001b[39;00m\n\u001b[0;32m   2261\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_invalid \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affine \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 2262\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_x \u001b[39m==\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_y:\n\u001b[0;32m   2263\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_affine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_x\u001b[39m.\u001b[39mget_affine()\n\u001b[0;32m   2264\u001b[0m         \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:1779\u001b[0m, in \u001b[0;36mAffineBase.__eq__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__eq__\u001b[39m(\u001b[39mself\u001b[39m, other):\n\u001b[0;32m   1778\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(other, \u001b[39m\"\u001b[39m\u001b[39mis_affine\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39m(other, \u001b[39m\"\u001b[39m\u001b[39mget_matrix\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m-> 1779\u001b[0m         \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mall(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_matrix() \u001b[39m==\u001b[39m other\u001b[39m.\u001b[39;49mget_matrix())\n\u001b[0;32m   1780\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mNotImplemented\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:1570\u001b[0m, in \u001b[0;36mTransform.get_matrix\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_matrix\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m   1569\u001b[0m     \u001b[39m\"\"\"Get the matrix for the affine part of this transform.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1570\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39mget_matrix()\n",
      "File \u001b[1;32mc:\\Users\\Jeroen\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\transforms.py:2446\u001b[0m, in \u001b[0;36mCompositeGenericTransform.get_affine\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_b\u001b[39m.\u001b[39mget_affine()\n\u001b[0;32m   2445\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2446\u001b[0m     \u001b[39mreturn\u001b[39;00m Affine2D(np\u001b[39m.\u001b[39;49mdot(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_b\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix(),\n\u001b[0;32m   2447\u001b[0m                            \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_a\u001b[39m.\u001b[39;49mget_affine()\u001b[39m.\u001b[39;49mget_matrix()))\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent = SarsaAgent(env, exploration_rate=1, learning_rate=0.5, discount_factor=0.3)\n",
    "\n",
    "imgs = []\n",
    "rewards = 0.0\n",
    "state = env.reset()\n",
    "\n",
    "goal_pos = env.unwrapped.maze.objects.goal.positions[0]\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action = agent.select_action(state)\n",
    "    next_state, reward, _, _ = env.step(action)\n",
    "    if tuple(next_state) == tuple(goal_pos):\n",
    "        done = True\n",
    "    state = next_state\n",
    "    rewards += reward\n",
    "    imgs.append(env.render(\"rgb_array\"))\n",
    "\n",
    "print(rewards)\n",
    "\n",
    "animate_run(imgs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 3. Play with parameters and analyse results\n",
    " \n",
    "Finally, you will describe, evaluate and interpret your results from two RL agents, as well as compare your agents with the given Random agent. Feel free to use the provided helper functions for evaluating your agents. Some points are good to notice:\n",
    "\n",
    "- Both quantified evaluation and human evaluation are needed in the report. The quantified evaluation shall focus on the measurement of reward. In human evaluation, you can use the provided visual tools to interpret your results. Your report shall include at least one plot presenting comparable measures of the different agents. \n",
    "\n",
    "- While evaluating the results of Agent 2 (with SARSA algorithm), please try at least 2 different values of **epsilon** (expect 0) and discuss the influence of different epsilon values on results. In the end, please identify a reasonable epsilon value that could balance the exploration and exploitation, then fix this value for comparing two agents. Present your trails and results in the report.\n",
    "\n",
    "- In the report, you also need to parcitularly describe and discuss the similarity and difference of results from two RL agents (hint: on-policy VS off-policy). For this, please make sure that the compared results are obtained from the same environment (a same maze for two different agents). Also, while evaluating the results of two agents, please try at least 2 different values of **gamma**. In this way, you could discuss the influence of this discount factor in your report. \n",
    "\n",
    "- Please run the simulation for multiple times and average them for all your results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: evaluation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Tasks \n",
    "\n",
    "We would like to challenge you with the following bonus task. For each task that is successfully completed, you may obtain max. 1 extra point. \n",
    "\n",
    "1. Implement a third RL agent using another RL algorithm (e.g. Monte Carlo methods, Expected SARSA or even neural network-based ones) and discuss your findings. Compare this third agent with the above ones and explain why this is a better (or worse) RL algorithm. You are allowed to reuse exsiting packages, but please cite them, test them in advance, and make sure that you can explain the used algorithm using your own words.\n",
    "\n",
    "2. Can you explore and show other evaluation results? If so, implement and present one extra result (e.g. a plot). And please explain why it is a good evaluation for our task or how it shows the difference between two RL agents/algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "f39bcb8a29cd463dfca303a4817756a4cf6503953b6bd703533cfd2fe3c1e21d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
